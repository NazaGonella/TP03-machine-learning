{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.data_handler as data_handler\n",
    "import src.models as models\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "CANTIDAD_DE_CLASES = 48\n",
    "SEED = 42\n",
    "\n",
    "X_images : np.ndarray[float] = np.load(f\"{project_root}/TP03/data/X_images.npy\")\n",
    "y_images : np.ndarray[float] = np.load(f\"{project_root}/TP03/data/y_images.npy\")\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b03d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_images = np.array([[0 if y_images[x] != i else 1 for i in range(CANTIDAD_DE_CLASES)] for x in range(len(X_images))], dtype=float)\n",
    "X_images = X_images / 255\n",
    "X_train : pd.DataFrame\n",
    "X_validation : pd.DataFrame\n",
    "X_test : pd.DataFrame\n",
    "X_train, X_validation, X_test, Y_train, Y_validation, Y_test = data_handler.get_splitted_dataset(pd.DataFrame(X_images), pd.DataFrame(y_images), seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94b6e6",
   "metadata": {},
   "source": [
    "## 3 ) Implementación y Entrenamiento de una Red Neuronal Avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44625781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes batch sizes\n",
    "# for i in range(4, 11, 1):\n",
    "#     print(f\"\\nBATCH SIZE = 2^{i}\")\n",
    "#     M1_batch_sizes : models.RedNeuronal = models.RedNeuronal([100,80], ['relu', 'relu', 'softmax'])\n",
    "#     M1_batch_sizes.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.0001], \n",
    "#         batch_size_2_pow=i, \n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# output\n",
    "\n",
    "# BATCH SIZE = 2^4\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.4172952929689673\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.872721248866749\n",
    "# -> Difference = +2.4554259558977813\n",
    "\n",
    "# BATCH SIZE = 2^5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.068959884185001\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.852873102551695\n",
    "# -> Difference = +1.7839132183666937\n",
    "\n",
    "# BATCH SIZE = 2^6\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.503137802246227\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.8621948632425784\n",
    "# -> Difference = +2.3590570609963515\n",
    "\n",
    "# BATCH SIZE = 2^7\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1309850462552273\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.8645668214647095\n",
    "# -> Difference = +2.7335817752094824\n",
    "\n",
    "# BATCH SIZE = 2^8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.5913105224784112\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 4.343482088518529\n",
    "# -> Difference = +2.752171566040118\n",
    "\n",
    "# BATCH SIZE = 2^9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.237209996813813\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.124517962619984\n",
    "# -> Difference = +1.887307965806171\n",
    "\n",
    "# BATCH SIZE = 2^10\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1415337620477084\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9448982327931914\n",
    "# -> Difference = -0.196635529254517\n",
    "\n",
    "\n",
    "# Mejores valores:\n",
    "# -> 7\n",
    "# -> 8\n",
    "# -> 9\n",
    "# -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7deb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes K (Rate Schedule Lineal)\n",
    "# for i in np.arange(1, 8.5, 0.5):\n",
    "#     print(f\"\\nK = epochs / {i}\")\n",
    "#     M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([100,80], ['relu', 'relu', 'softmax'])\n",
    "#     M1_rs_lineal.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.00001], \n",
    "#         batch_size_2_pow=10, \n",
    "#         K=250/i,\n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# outputs\n",
    "\n",
    "# K = epochs / 1.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2315667779944102\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9282257182237148\n",
    "# -> Difference = -0.30334105977069536\n",
    "\n",
    "# K = epochs / 1.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.346495934081243\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1818148551876257\n",
    "# -> Difference = -0.16468107889361727\n",
    "\n",
    "# K = epochs / 2.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.5599001239326573\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.402887814776599\n",
    "# -> Difference = -0.15701230915605824\n",
    "\n",
    "# K = epochs / 2.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.731865305547131\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5258190848871978\n",
    "# -> Difference = -0.20604622065993317\n",
    "\n",
    "# K = epochs / 3.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8636290164349694\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6226172057698403\n",
    "# -> Difference = -0.2410118106651291\n",
    "\n",
    "# K = epochs / 3.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0226895757399648\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.7060331396745363\n",
    "# -> Difference = -0.3166564360654285\n",
    "\n",
    "# K = epochs / 4.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1862231460082713\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.828541719543326\n",
    "# -> Difference = -0.3576814264649453\n",
    "\n",
    "# K = epochs / 4.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.324613594060876\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.8876569007450925\n",
    "# -> Difference = -0.43695669331578335\n",
    "\n",
    "# K = epochs / 5.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.4534161910034094\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.997947726239879\n",
    "# -> Difference = -0.4554684647635303\n",
    "\n",
    "# K = epochs / 5.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.412223367604805\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.9569275663675696\n",
    "# -> Difference = -0.45529580123723523\n",
    "\n",
    "# K = epochs / 6.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.5613487370913166\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.061727294061561\n",
    "# -> Difference = -0.4996214430297554\n",
    "\n",
    "# K = epochs / 6.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.4108588457869686\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.977536450763072\n",
    "# -> Difference = -0.4333223950238967\n",
    "\n",
    "# K = epochs / 7.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.5995276947504014\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.0628029805683292\n",
    "# -> Difference = -0.5367247141820721\n",
    "\n",
    "# K = epochs / 7.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.807883956748906\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.254359809981865\n",
    "# -> Difference = -0.5535241467670406\n",
    "\n",
    "# K = epochs / 8.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.742118356668183\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.1558404021967\n",
    "# -> Difference = -0.5862779544714831\n",
    "\n",
    "\n",
    "# Mejores Valores:\n",
    "# -> K = epochs / 1.0\n",
    "# -> K = epochs / 1.5\n",
    "# -> K = epochs / 7.5\n",
    "# -> K = epochs / 8.0\n",
    "# La diferencia de Loss entre épocas es mayor a medida se aumenta K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4488301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes S (Rate Schedule Exponencial)\n",
    "# con c = -0.5\n",
    "# for i in np.arange(1, 8.5, 0.5):\n",
    "#     print(f\"\\nS = epochs / {i}\")\n",
    "#     M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([100,80], ['relu', 'relu', 'softmax'])\n",
    "#     M1_rs_lineal.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.00001], \n",
    "#         batch_size_2_pow=10, \n",
    "#         S = 250 / i,\n",
    "#         c = -0.5,\n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# outputs\n",
    "\n",
    "# S = epochs / 1.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2315667779944102\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9282257182237149\n",
    "# -> Difference = -0.30334105977069525\n",
    "\n",
    "# S = epochs / 1.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2279800986162261\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.934442884522318\n",
    "# -> Difference = -0.2935372140939081\n",
    "\n",
    "# S = epochs / 2.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.27159213924753\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9733160030805783\n",
    "# -> Difference = -0.2982761361669517\n",
    "\n",
    "# S = epochs / 2.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2561138691269322\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9592860523539999\n",
    "# -> Difference = -0.29682781677293235\n",
    "\n",
    "# S = epochs / 3.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.254764903238054\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9703015449309709\n",
    "# -> Difference = -0.284463358307083\n",
    "\n",
    "# S = epochs / 3.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2392888075717492\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9572990855764858\n",
    "# -> Difference = -0.2819897219952634\n",
    "\n",
    "# S = epochs / 4.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2396458694007957\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9494928606444151\n",
    "# -> Difference = -0.2901530087563806\n",
    "\n",
    "# S = epochs / 4.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2182932524777628\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9143984963273055\n",
    "# -> Difference = -0.30389475615045725\n",
    "\n",
    "# S = epochs / 5.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2660397495247033\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9607409005321466\n",
    "# -> Difference = -0.30529884899255677\n",
    "\n",
    "# S = epochs / 5.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.231261411530577\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9455057707748208\n",
    "# -> Difference = -0.2857556407557563\n",
    "\n",
    "# S = epochs / 6.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2662249524660232\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9660696978410621\n",
    "# -> Difference = -0.30015525462496107\n",
    "\n",
    "# S = epochs / 6.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2266666745874328\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9417029115538114\n",
    "# -> Difference = -0.2849637630336215\n",
    "\n",
    "# S = epochs / 7.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2318325649500805\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9540861023732001\n",
    "# -> Difference = -0.2777464625768804\n",
    "\n",
    "# S = epochs / 7.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.23548550539208\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9268702820964739\n",
    "# -> Difference = -0.308615223295606\n",
    "\n",
    "# S = epochs / 8.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2184017920804486\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9384180833074381\n",
    "# -> Difference = -0.2799837087730105\n",
    "\n",
    "\n",
    "# Mejores valores:\n",
    "# -> S = epochs / 1.0\n",
    "# -> S = epochs / 4.5\n",
    "# -> S = epochs / 8.0\n",
    "# -> S = epochs / 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.130944684702892\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.640320387428479\n",
      "-> Difference = -0.49062429727441303\n",
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1547714274401435\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6593621238243639\n",
      "-> Difference = -0.4954093036157796\n",
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1069952046014864\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6302142352522795\n",
      "-> Difference = -0.4767809693492069\n",
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1549388333725186\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6684989724566273\n",
      "-> Difference = -0.4864398609158913\n",
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.3157641800775837\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.7959323901547175\n",
      "-> Difference = -0.5198317899228662\n",
      "\n",
      "B1 = 0.8\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.562292652356077\n",
      "Epoch 250\n",
      "-> Loss Mean = 2.0475878272413626\n",
      "-> Difference = -0.5147048251147144\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.140604729365676\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6670220769861799\n",
      "-> Difference = -0.47358265237949615\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.169014663957456\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.655660956941914\n",
      "-> Difference = -0.5133537070155418\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1691324265250636\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6785474020253954\n",
      "-> Difference = -0.4905850244996681\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.161141769211036\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6779857323301641\n",
      "-> Difference = -0.48315603688087183\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.357917540140231\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.8366704637398779\n",
      "-> Difference = -0.521247076400353\n",
      "\n",
      "B1 = 0.85\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.406342790862181\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.9742332017749298\n",
      "-> Difference = -0.4321095890872513\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0218989942015213\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.5857677366142418\n",
      "-> Difference = -0.43613125758727955\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1438879081596047\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6612191605604971\n",
      "-> Difference = -0.4826687475991076\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0803691497480754\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6180631668620995\n",
      "-> Difference = -0.4623059828859759\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.112422492162805\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6371716970077128\n",
      "-> Difference = -0.4752507951550924\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.3092069759202336\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.8052870352823207\n",
      "-> Difference = -0.5039199406379129\n",
      "\n",
      "B1 = 0.9\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.480714022513358\n",
      "Epoch 250\n",
      "-> Loss Mean = 2.007200224914241\n",
      "-> Difference = -0.47351379759911705\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0272153597976468\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.579876464770004\n",
      "-> Difference = -0.4473388950276427\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0490263666901507\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6104795739671545\n",
      "-> Difference = -0.43854679272299624\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0719565696737603\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6181166066153776\n",
      "-> Difference = -0.4538399630583827\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0360058719594045\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.5880758785850597\n",
      "-> Difference = -0.4479299933743448\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.334012875804927\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.8232659461375529\n",
      "-> Difference = -0.5107469296673739\n",
      "\n",
      "B1 = 0.95\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.3639832930028413\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.9596960846879734\n",
      "-> Difference = -0.40428720831486786\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.996385216651882\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.569324524070626\n",
      "-> Difference = -0.4270606925812561\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.8946574381702779\n",
      "Epoch 250\n",
      "-> Loss Mean = 21.027548189753\n",
      "-> Difference = +19.13289075158272\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.936723739219874\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.5544816621809963\n",
      "-> Difference = -0.3822420770388777\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.7847881161879806\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.4525209162929698\n",
      "-> Difference = -0.33226719989501086\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.9741560156843807\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.567225244434891\n",
      "-> Difference = -0.4069307712494896\n",
      "\n",
      "B1 = 0.99\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.1087530999033897\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.7549037160849013\n",
      "-> Difference = -0.3538493838184884\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.8\n",
      "Epoch 125\n",
      "-> Loss Mean = 22.148889810540282\n",
      "Epoch 250\n",
      "-> Loss Mean = 22.19386217563763\n",
      "-> Difference = +0.04497236509734748\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.85\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.219611776265537\n",
      "Epoch 250\n",
      "-> Loss Mean = 2.858886677087743\n",
      "-> Difference = +0.6392749008222056\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.9\n",
      "Epoch 125\n",
      "-> Loss Mean = 2.0787120352700255\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.759234652248873\n",
      "-> Difference = -0.31947738302115236\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.95\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.9324808492355872\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.6554377441350017\n",
      "-> Difference = -0.2770431051005855\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.99\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.791763917116874\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.3522330293984401\n",
      "-> Difference = -0.43953088771843385\n",
      "\n",
      "B1 = 0.999\n",
      "B2 = 0.999\n",
      "Epoch 125\n",
      "-> Loss Mean = 1.9179873259755336\n",
      "Epoch 250\n",
      "-> Loss Mean = 1.5226735365795014\n",
      "-> Difference = -0.3953137893960321\n"
     ]
    }
   ],
   "source": [
    "# Pruebo diferentes combinaciones de b1 y b2 (Adam)\n",
    "# valores comunes para parámetros de Adam:\n",
    "# b1 = [0.85, 0.9, 0.95]\n",
    "# b2 = [0.95, 0.99, 0.999]\n",
    "for b1 in [0.8, 0.85, 0.9, 0.95, 0.99, 0.999]:\n",
    "    for b2 in [0.8, 0.85, 0.9, 0.95, 0.99, 0.999]:\n",
    "        print(f\"\\nB1 = {b1}\")\n",
    "        print(f\"B2 = {b2}\")\n",
    "        M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([100,80], ['relu', 'relu', 'softmax'])\n",
    "        M1_rs_lineal.stochastic_gradient_descent(\n",
    "            np.array(X_train), \n",
    "            np.array(Y_train),\n",
    "            epochs=250, \n",
    "            learning_rate=[0.0001, 0.00001], \n",
    "            batch_size_2_pow=10, \n",
    "            use_adam=True,\n",
    "            b1=b1,\n",
    "            b2=b2,\n",
    "            print_results_rate=125\n",
    "        )\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.130944684702892\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.640320387428479\n",
    "# -> Difference = -0.49062429727441303\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1547714274401435\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6593621238243639\n",
    "# -> Difference = -0.4954093036157796\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1069952046014864\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6302142352522795\n",
    "# -> Difference = -0.4767809693492069\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1549388333725186\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6684989724566273\n",
    "# -> Difference = -0.4864398609158913\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.3157641800775837\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.7959323901547175\n",
    "# -> Difference = -0.5198317899228662\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.562292652356077\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.0475878272413626\n",
    "# -> Difference = -0.5147048251147144\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.140604729365676\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6670220769861799\n",
    "# -> Difference = -0.47358265237949615\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.169014663957456\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.655660956941914\n",
    "# -> Difference = -0.5133537070155418\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1691324265250636\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6785474020253954\n",
    "# -> Difference = -0.4905850244996681\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.161141769211036\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6779857323301641\n",
    "# -> Difference = -0.48315603688087183\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.357917540140231\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.8366704637398779\n",
    "# -> Difference = -0.521247076400353\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.406342790862181\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.9742332017749298\n",
    "# -> Difference = -0.4321095890872513\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0218989942015213\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5857677366142418\n",
    "# -> Difference = -0.43613125758727955\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1438879081596047\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6612191605604971\n",
    "# -> Difference = -0.4826687475991076\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0803691497480754\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6180631668620995\n",
    "# -> Difference = -0.4623059828859759\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.112422492162805\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6371716970077128\n",
    "# -> Difference = -0.4752507951550924\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.3092069759202336\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.8052870352823207\n",
    "# -> Difference = -0.5039199406379129\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.480714022513358\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.007200224914241\n",
    "# -> Difference = -0.47351379759911705\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0272153597976468\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.579876464770004\n",
    "# -> Difference = -0.4473388950276427\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0490263666901507\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6104795739671545\n",
    "# -> Difference = -0.43854679272299624\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0719565696737603\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6181166066153776\n",
    "# -> Difference = -0.4538399630583827\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0360058719594045\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5880758785850597\n",
    "# -> Difference = -0.4479299933743448\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.334012875804927\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.8232659461375529\n",
    "# -> Difference = -0.5107469296673739\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.3639832930028413\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.9596960846879734\n",
    "# -> Difference = -0.40428720831486786\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.996385216651882\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.569324524070626\n",
    "# -> Difference = -0.4270606925812561\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8946574381702779\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 21.027548189753\n",
    "# -> Difference = +19.13289075158272\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.936723739219874\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5544816621809963\n",
    "# -> Difference = -0.3822420770388777\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7847881161879806\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.4525209162929698\n",
    "# -> Difference = -0.33226719989501086\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9741560156843807\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.567225244434891\n",
    "# -> Difference = -0.4069307712494896\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1087530999033897\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.7549037160849013\n",
    "# -> Difference = -0.3538493838184884\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 22.148889810540282\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 22.19386217563763\n",
    "# -> Difference = +0.04497236509734748\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.219611776265537\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.858886677087743\n",
    "# -> Difference = +0.6392749008222056\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0787120352700255\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.759234652248873\n",
    "# -> Difference = -0.31947738302115236\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9324808492355872\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6554377441350017\n",
    "# -> Difference = -0.2770431051005855\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.791763917116874\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.3522330293984401\n",
    "# -> Difference = -0.43953088771843385\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9179873259755336\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5226735365795014\n",
    "# -> Difference = -0.3953137893960321\n",
    "\n",
    "# Mejores valores:\n",
    "# -> B1 = 0.999\n",
    "#    B2 = 0.99\n",
    "# -> B1 = 0.999\n",
    "#    B2 = 0.999\n",
    "# -> B1 = 0.99\n",
    "#    B2 = 0.95\n",
    "# -> B1 = 0.99\n",
    "#    B2 = 0.9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
