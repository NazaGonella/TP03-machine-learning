{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "692055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import src.data_handler as data_handler\n",
    "import src.models as models\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "CANTIDAD_DE_CLASES = 48\n",
    "SEED = 42\n",
    "\n",
    "X_images : np.ndarray[float] = np.load(f\"{project_root}/TP03/data/X_images.npy\")\n",
    "y_images : np.ndarray[float] = np.load(f\"{project_root}/TP03/data/y_images.npy\")\n",
    "\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b03d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_images = np.array([[0 if y_images[x] != i else 1 for i in range(CANTIDAD_DE_CLASES)] for x in range(len(X_images))], dtype=float)\n",
    "X_images = X_images / 255\n",
    "X_train : pd.DataFrame\n",
    "X_validation : pd.DataFrame\n",
    "X_test : pd.DataFrame\n",
    "X_train, X_validation, X_test, Y_train, Y_validation, Y_test = data_handler.get_splitted_dataset(pd.DataFrame(X_images), pd.DataFrame(y_images), seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a94b6e6",
   "metadata": {},
   "source": [
    "## 3 ) Implementación y Entrenamiento de una Red Neuronal Avanzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44625781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes batch sizes\n",
    "# for i in range(4, 11, 1):\n",
    "#     print(f\"\\nBATCH SIZE = 2^{i}\")\n",
    "#     M1_batch_sizes : models.RedNeuronal = models.RedNeuronal([784,100,80,48], ['relu', 'relu', 'softmax'])\n",
    "#     M1_batch_sizes.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.0001], \n",
    "#         batch_size_2_pow=i, \n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# output\n",
    "\n",
    "# BATCH SIZE = 2^4\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.4172952929689673\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.872721248866749\n",
    "# -> Difference = +2.4554259558977813\n",
    "\n",
    "# BATCH SIZE = 2^5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.068959884185001\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.852873102551695\n",
    "# -> Difference = +1.7839132183666937\n",
    "\n",
    "# BATCH SIZE = 2^6\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.503137802246227\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.8621948632425784\n",
    "# -> Difference = +2.3590570609963515\n",
    "\n",
    "# BATCH SIZE = 2^7\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1309850462552273\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.8645668214647095\n",
    "# -> Difference = +2.7335817752094824\n",
    "\n",
    "# BATCH SIZE = 2^8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.5913105224784112\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 4.343482088518529\n",
    "# -> Difference = +2.752171566040118\n",
    "\n",
    "# BATCH SIZE = 2^9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.237209996813813\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.124517962619984\n",
    "# -> Difference = +1.887307965806171\n",
    "\n",
    "# BATCH SIZE = 2^10\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1415337620477084\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9448982327931914\n",
    "# -> Difference = -0.196635529254517\n",
    "\n",
    "\n",
    "# Mejores valores:\n",
    "# -> 7\n",
    "# -> 8\n",
    "# -> 9\n",
    "# -> 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b7deb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes K (Rate Schedule Lineal)\n",
    "# for i in np.arange(1, 8.5, 0.5):\n",
    "#     print(f\"\\nK = epochs / {i} = {int(round(250/i))}\")\n",
    "#     M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([784,100,80,48], ['relu', 'relu', 'softmax'])\n",
    "#     M1_rs_lineal.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.00001], \n",
    "#         batch_size_2_pow=10, \n",
    "#         K=int(round(250/i)),\n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# outputs\n",
    "\n",
    "# K = epochs / 1.0 = 250\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2315667779944102\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9282257182237148\n",
    "# -> Difference = -0.30334105977069536\n",
    "\n",
    "# K = epochs / 1.5 = 167\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.3457219686135664\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.18082896379247\n",
    "# -> Difference = -0.16489300482109637\n",
    "\n",
    "# K = epochs / 2.0 = 125\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.5599001239326573\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.402887814776599\n",
    "# -> Difference = -0.15701230915605824\n",
    "\n",
    "# K = epochs / 2.5 = 100\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.731865305547131\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.5258190848871978\n",
    "# -> Difference = -0.20604622065993317\n",
    "\n",
    "# K = epochs / 3.0 = 83\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8668644240816181\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.6246906793329419\n",
    "# -> Difference = -0.24217374474867626\n",
    "\n",
    "# K = epochs / 3.5 = 71\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.028664632482819\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.7096246003050268\n",
    "# -> Difference = -0.3190400321777922\n",
    "\n",
    "# K = epochs / 4.0 = 62\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.193718177981163\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.8334227580855653\n",
    "# -> Difference = -0.3602954198955979\n",
    "\n",
    "# K = epochs / 4.5 = 56\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.3154135465234127\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.882055754810544\n",
    "# -> Difference = -0.4333577917128686\n",
    "\n",
    "# K = epochs / 5.0 = 50\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.4534161910034094\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.997947726239879\n",
    "# -> Difference = -0.4554684647635303\n",
    "\n",
    "# K = epochs / 5.5 = 45\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.4208210545797697\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.9626379885146958\n",
    "# -> Difference = -0.45818306606507386\n",
    "\n",
    "# K = epochs / 6.0 = 42\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.5536363593431286\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.0566346996991447\n",
    "# -> Difference = -0.4970016596439839\n",
    "\n",
    "# K = epochs / 6.5 = 38\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.4199395417680583\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.982755603538604\n",
    "# -> Difference = -0.4371839382294542\n",
    "\n",
    "# K = epochs / 7.0 = 36\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.591578743678074\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.0582109992993223\n",
    "# -> Difference = -0.5333677443787517\n",
    "\n",
    "# K = epochs / 7.5 = 33\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.8145412582937697\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.2594012716020897\n",
    "# -> Difference = -0.55513998669168\n",
    "\n",
    "# K = epochs / 8.0 = 31\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.7476434093148048\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.1596900099530254\n",
    "# -> Difference = -0.5879533993617794\n",
    "\n",
    "\n",
    "# Mejores Valores:\n",
    "# -> K = epochs / 1.0\n",
    "# -> K = epochs / 1.5\n",
    "# -> K = epochs / 7.5\n",
    "# -> K = epochs / 8.0\n",
    "# La diferencia de Loss entre épocas es mayor a medida se aumenta K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4488301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes S (Rate Schedule Exponencial)\n",
    "# con c = -0.5\n",
    "# for i in np.arange(1, 8.5, 0.5):\n",
    "#     print(f\"\\nS = epochs / {i}\")\n",
    "#     M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([784,100,80,48], ['relu', 'relu', 'softmax'])\n",
    "#     M1_rs_lineal.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.00001], \n",
    "#         batch_size_2_pow=10, \n",
    "#         S = 250 / i,\n",
    "#         c = -0.5,\n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# outputs\n",
    "\n",
    "# S = epochs / 1.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2315667779944102\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9282257182237149\n",
    "# -> Difference = -0.30334105977069525\n",
    "\n",
    "# S = epochs / 1.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2279800986162261\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.934442884522318\n",
    "# -> Difference = -0.2935372140939081\n",
    "\n",
    "# S = epochs / 2.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.27159213924753\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9733160030805783\n",
    "# -> Difference = -0.2982761361669517\n",
    "\n",
    "# S = epochs / 2.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2561138691269322\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9592860523539999\n",
    "# -> Difference = -0.29682781677293235\n",
    "\n",
    "# S = epochs / 3.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.254764903238054\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9703015449309709\n",
    "# -> Difference = -0.284463358307083\n",
    "\n",
    "# S = epochs / 3.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2392888075717492\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9572990855764858\n",
    "# -> Difference = -0.2819897219952634\n",
    "\n",
    "# S = epochs / 4.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2396458694007957\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9494928606444151\n",
    "# -> Difference = -0.2901530087563806\n",
    "\n",
    "# S = epochs / 4.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2182932524777628\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9143984963273055\n",
    "# -> Difference = -0.30389475615045725\n",
    "\n",
    "# S = epochs / 5.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2660397495247033\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9607409005321466\n",
    "# -> Difference = -0.30529884899255677\n",
    "\n",
    "# S = epochs / 5.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.231261411530577\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9455057707748208\n",
    "# -> Difference = -0.2857556407557563\n",
    "\n",
    "# S = epochs / 6.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2662249524660232\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9660696978410621\n",
    "# -> Difference = -0.30015525462496107\n",
    "\n",
    "# S = epochs / 6.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2266666745874328\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9417029115538114\n",
    "# -> Difference = -0.2849637630336215\n",
    "\n",
    "# S = epochs / 7.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2318325649500805\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9540861023732001\n",
    "# -> Difference = -0.2777464625768804\n",
    "\n",
    "# S = epochs / 7.5\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.23548550539208\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9268702820964739\n",
    "# -> Difference = -0.308615223295606\n",
    "\n",
    "# S = epochs / 8.0\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2184017920804486\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9384180833074381\n",
    "# -> Difference = -0.2799837087730105\n",
    "\n",
    "\n",
    "# Mejores valores:\n",
    "# -> S = epochs / 1.0\n",
    "# -> S = epochs / 4.5\n",
    "# -> S = epochs / 8.0\n",
    "# -> S = epochs / 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b23763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes combinaciones de B1 y B2 (Adam)\n",
    "# valores comunes para parámetros de Adam:\n",
    "# b1 = [0.85, 0.9, 0.95]\n",
    "# b2 = [0.95, 0.99, 0.999]\n",
    "# for b1 in [0.8, 0.85, 0.9, 0.95, 0.99, 0.999]:\n",
    "#     for b2 in [0.8, 0.85, 0.9, 0.95, 0.99, 0.999]:\n",
    "#         print(f\"\\nB1 = {b1}\")\n",
    "#         print(f\"B2 = {b2}\")\n",
    "#         M1_rs_lineal : models.RedNeuronal = models.RedNeuronal([784,100,80,48], ['relu', 'relu', 'softmax'])\n",
    "#         M1_rs_lineal.stochastic_gradient_descent(\n",
    "#             np.array(X_train), \n",
    "#             np.array(Y_train),\n",
    "#             epochs=250, \n",
    "#             learning_rate=[0.0001, 0.0001], \n",
    "#             batch_size_2_pow=10, \n",
    "#             use_adam=True,\n",
    "#             b1=b1,\n",
    "#             b2=b2,\n",
    "#             print_results_rate=125\n",
    "#         )\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7772490205564546\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9639208596747603\n",
    "# -> Difference = -0.8133281608816944\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7983328000649013\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9838414169872784\n",
    "# -> Difference = -0.8144913830776228\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7607794740484755\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9893162812603814\n",
    "# -> Difference = -0.771463192788094\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8052086836089671\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.001376278851238\n",
    "# -> Difference = -0.8038324047577292\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9510067638275015\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1222462163537101\n",
    "# -> Difference = -0.8287605474737914\n",
    "\n",
    "# B1 = 0.8\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.162745869801885\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.3225639985527846\n",
    "# -> Difference = -0.8401818712491003\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7999609420546678\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9977574691931932\n",
    "# -> Difference = -0.8022034728614746\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.798068963360069\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9548216146609436\n",
    "# -> Difference = -0.8432473486991254\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8159731602463947\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.0158137090153114\n",
    "# -> Difference = -0.8001594512310832\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8163240591156158\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.0149400954495191\n",
    "# -> Difference = -0.8013839636660967\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.000600466751602\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1251001938259066\n",
    "# -> Difference = -0.8755002729256955\n",
    "\n",
    "# B1 = 0.85\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.078086135678435\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.3342131161697164\n",
    "# -> Difference = -0.7438730195087186\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7053035881717984\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9601541105674611\n",
    "# -> Difference = -0.7451494776043373\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7979887343348615\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9719501225201559\n",
    "# -> Difference = -0.8260386118147056\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.747080045171262\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9923929049795421\n",
    "# -> Difference = -0.7546871401917199\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7713394597958545\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9932174300782322\n",
    "# -> Difference = -0.7781220297176223\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9661058428118556\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1222052547226222\n",
    "# -> Difference = -0.8439005880892334\n",
    "\n",
    "# B1 = 0.9\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.1198485219230068\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.3143973380613372\n",
    "# -> Difference = -0.8054511838616696\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7359165937813512\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9822689844351626\n",
    "# -> Difference = -0.7536476093461886\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7439409260045875\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.0122078843606628\n",
    "# -> Difference = -0.7317330416439247\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7420183818955586\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9713205953858455\n",
    "# -> Difference = -0.7706977865097131\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.713992644969066\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.955531323085762\n",
    "# -> Difference = -0.7584613218833038\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9823285772161083\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1141049453740333\n",
    "# -> Difference = -0.8682236318420751\n",
    "\n",
    "# B1 = 0.95\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0584884572132047\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.3331926942923464\n",
    "# -> Difference = -0.7252957629208583\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.9194829327123957\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 22.12640362799161\n",
    "# -> Difference = +20.206920695279216\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.753760525407771\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1444816278394123\n",
    "# -> Difference = -0.6092788975683587\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.7613764139245738\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1592166088031157\n",
    "# -> Difference = -0.6021598051214581\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.5711968091365154\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9890369904033487\n",
    "# -> Difference = -0.5821598187331667\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.6961132465457276\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9941542919174201\n",
    "# -> Difference = -0.7019589546283075\n",
    "\n",
    "# B1 = 0.99\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.827154957442074\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.2084058959905646\n",
    "# -> Difference = -0.6187490614515094\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.8\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 22.009892572040744\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 22.058945080345595\n",
    "# -> Difference = +0.049052508304850306\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.85\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.067561520696059\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 6.878628816964356\n",
    "# -> Difference = +4.8110672962682965\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.9\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 2.0831593557943204\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 2.5461054926145916\n",
    "# -> Difference = +0.4629461368202712\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.95\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.800115137420336\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.4678725883521437\n",
    "# -> Difference = -0.3322425490681922\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.99\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.6069005465455553\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9377605121728853\n",
    "# -> Difference = -0.66914003437267\n",
    "\n",
    "# B1 = 0.999\n",
    "# B2 = 0.999\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.6909541426207872\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.0714718472439175\n",
    "# -> Difference = -0.6194822953768697\n",
    "\n",
    "# Mejores valores:\n",
    "# -> B1 = 0.999\n",
    "#    B2 = 0.99\n",
    "# -> B1 = 0.85\n",
    "#    B2 = 0.85\n",
    "# -> B1 = 0.95\n",
    "#    B2 = 0.95\n",
    "# -> B1 = 0.9\n",
    "#    B2 = 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47874b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruebo diferentes L2 (Regularización L2)\n",
    "# for l2_exp in range(3, -6, -1):\n",
    "#     print(f\"\\nL2 = {10**l2_exp}\")\n",
    "#     M1 : models.RedNeuronal = models.RedNeuronal([784,100,80,48], ['relu', 'relu', 'softmax'])\n",
    "#     M1.stochastic_gradient_descent(\n",
    "#         np.array(X_train), \n",
    "#         np.array(Y_train),\n",
    "#         epochs=250, \n",
    "#         learning_rate=[0.0001, 0.0001], \n",
    "#         batch_size_2_pow=10, \n",
    "#         L2=10**l2_exp,\n",
    "#         print_results_rate=125\n",
    "#     )\n",
    "\n",
    "# output:\n",
    "\n",
    "# L2 = 1000\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 3.529896700969622\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 3.154754735208252\n",
    "# -> Difference = -0.3751419657613697\n",
    "\n",
    "# L2 = 100\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.8320888855557524\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.4721796749388958\n",
    "# -> Difference = -0.35990921061685666\n",
    "\n",
    "# L2 = 10\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.2211964751367268\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.9547285923058941\n",
    "# -> Difference = -0.26646788283083267\n",
    "\n",
    "# L2 = 1\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1679356882332232\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.8247530396746727\n",
    "# -> Difference = -0.3431826485585505\n",
    "\n",
    "# L2 = 0.1\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1220241383402538\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.36359759909518\n",
    "# -> Difference = +0.24157346075492625\n",
    "\n",
    "# L2 = 0.01\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1006828117873595\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.1026206058737746\n",
    "# -> Difference = +0.0019377940864151455\n",
    "\n",
    "# L2 = 0.001\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1423622218425207\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.2426144683853708\n",
    "# -> Difference = +0.10025224654285014\n",
    "\n",
    "# L2 = 0.0001\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.060911088368837\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 1.0485479311999377\n",
    "# -> Difference = -0.012363157168899352\n",
    "\n",
    "# L2 = 1e-05\n",
    "# Epoch 125\n",
    "# -> Loss Mean = 1.1213377292808744\n",
    "# Epoch 250\n",
    "# -> Loss Mean = 0.8520883823783536\n",
    "# -> Difference = -0.2692493469025208\n",
    "\n",
    "\n",
    "# Mejores valores:\n",
    "# -> 0.00001\n",
    "# -> 0.0001\n",
    "# -> 1\n",
    "# -> 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d20664",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84b4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = data_handler.get_train_and_test_split(pd.DataFrame(X_images), pd.DataFrame(y_images), seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeb6942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIPERPARÁMETROS\n",
    "# Valores candidatos:\n",
    "# epochs : int = 250\n",
    "# batch_size_2_pow_values : list[int] = [1000, 10]\n",
    "# K_values : list[int] = [0, int(round(epochs/1.0)), int(round(epochs/7.5))]\n",
    "# S_values : list[float] =  [0, epochs / 1.0, epochs / 7.5]\n",
    "# b1_and_b2_values : list[float] =  [(0.999, 0.99), (0.85, 0.85), (0.9, 0.88)]\n",
    "# L2_values : list[float] = [0.00001, 0.0001, 1]\n",
    "# cross_validation : models.CrossValidation = models.CrossValidation(\n",
    "#     np.array(X_train),\n",
    "#     np.array(Y_train),\n",
    "#     epochs=epochs,\n",
    "#     num_folds=4,\n",
    "#     learning_rate_range=(0.0001, 0.00001),\n",
    "#     batch_size_2_pow_values=batch_size_2_pow_values,\n",
    "#     K_values=K_values,\n",
    "#     c_value=-0.5,\n",
    "#     S_values=S_values,\n",
    "#     b1_and_b2_values=b1_and_b2_values,\n",
    "#     L2_values=L2_values,\n",
    "# )\n",
    "# model_score : list[dict] = cross_validation.evaluate_hiperparameters(M=[784,100,80,48], h=['relu', 'relu', 'softmax'])\n",
    "# cross_validation.print_n_scores(model_score, 10)\n",
    "\n",
    "# output:\n",
    "# Cantidad de iteraciones estimada: 324\n",
    "# {'accuracy': np.float64(0.5780000000000001), 'model_index': 48, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 250, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.5762499999999999), 'model_index': 15, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 0, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.5762499999999999), 'model_index': 46, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 0, 'c': -0.5, 'S': 250.0}\n",
    "# {'accuracy': np.float64(0.5752499999999999), 'model_index': 25, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': (0.9, 0.88), 'K': 0, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.5745), 'model_index': 75, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 0, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.573), 'model_index': 50, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.85, 0.85), 'K': 0, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.573), 'model_index': 77, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 0, 'c': -0.5, 'S': 33.333333333333336}\n",
    "# {'accuracy': np.float64(0.5714999999999999), 'model_index': 58, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.9, 0.88), 'K': 250, 'c': -0.5, 'S': 0}\n",
    "# {'accuracy': np.float64(0.571), 'model_index': 76, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 0, 'c': -0.5, 'S': 250.0}\n",
    "# {'accuracy': np.float64(0.57075), 'model_index': 26, 'lr_range': (0.0001, 1e-05), 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': (0.9, 0.88), 'K': 0, 'c': -0.5, 'S': 250.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c00e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'accuracy': 0.195, 'model_index': 0, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.18000000000000002, 'model_index': 1, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.204, 'model_index': 2, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.188, 'model_index': 3, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.07700000000000001, 'model_index': 4, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.27499999999999997, 'model_index': 5, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.28, 'model_index': 6, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.28375, 'model_index': 7, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.272, 'model_index': 8, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.08174999999999999, 'model_index': 9, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.25925, 'model_index': 10, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.26175000000000004, 'model_index': 11, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.27449999999999997, 'model_index': 12, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.27525, 'model_index': 13, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.08049999999999999, 'model_index': 14, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5762499999999999, 'model_index': 15, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.56875, 'model_index': 16, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.566, 'model_index': 17, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5702499999999999, 'model_index': 18, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.41275, 'model_index': 19, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.56775, 'model_index': 20, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.56125, 'model_index': 21, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.56575, 'model_index': 22, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5652499999999999, 'model_index': 23, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.41175, 'model_index': 24, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5752499999999999, 'model_index': 25, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.57075, 'model_index': 26, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.56925, 'model_index': 27, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5625, 'model_index': 28, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.41100000000000003, 'model_index': 29, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.20350000000000001, 'model_index': 30, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.1995, 'model_index': 31, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.21400000000000002, 'model_index': 32, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.19999999999999998, 'model_index': 33, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.081, 'model_index': 34, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.27125, 'model_index': 35, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.27625, 'model_index': 36, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.271, 'model_index': 37, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.2735, 'model_index': 38, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.08175, 'model_index': 39, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.26975000000000005, 'model_index': 40, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.27025, 'model_index': 41, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.27249999999999996, 'model_index': 42, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.27449999999999997, 'model_index': 43, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.07375, 'model_index': 44, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.56775, 'model_index': 45, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5762499999999999, 'model_index': 46, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5700000000000001, 'model_index': 47, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5780000000000001, 'model_index': 48, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.41025, 'model_index': 49, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.573, 'model_index': 50, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5655, 'model_index': 51, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.56575, 'model_index': 52, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.56775, 'model_index': 53, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.42, 'model_index': 54, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.56775, 'model_index': 55, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5682499999999999, 'model_index': 56, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5665, 'model_index': 57, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5714999999999999, 'model_index': 58, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.41975, 'model_index': 59, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.204, 'model_index': 60, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.20025, 'model_index': 61, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.21675, 'model_index': 62, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.2075, 'model_index': 63, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.10025, 'model_index': 64, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.27999999999999997, 'model_index': 65, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.275, 'model_index': 66, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.2605, 'model_index': 67, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.2645, 'model_index': 68, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.077, 'model_index': 69, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.25025, 'model_index': 70, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.26325, 'model_index': 71, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.27925, 'model_index': 72, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.28625, 'model_index': 73, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.0915, 'model_index': 74, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5745, 'model_index': 75, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.571, 'model_index': 76, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.573, 'model_index': 77, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5635, 'model_index': 78, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.39949999999999997, 'model_index': 79, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.565, 'model_index': 80, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.56975, 'model_index': 81, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5682499999999999, 'model_index': 82, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.569, 'model_index': 83, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.407, 'model_index': 84, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.56775, 'model_index': 85, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5702499999999999, 'model_index': 86, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.56225, 'model_index': 87, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.563, 'model_index': 88, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.40575, 'model_index': 89, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.40575, 'model_index': 90, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.41525, 'model_index': 91, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.40625, 'model_index': 92, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.42625, 'model_index': 93, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.16250000000000003, 'model_index': 94, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.429, 'model_index': 95, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.41775, 'model_index': 96, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.42050000000000004, 'model_index': 97, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.414, 'model_index': 98, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.137, 'model_index': 99, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.40950000000000003, 'model_index': 100, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.40549999999999997, 'model_index': 101, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.427, 'model_index': 102, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.417, 'model_index': 103, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.15975, 'model_index': 104, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.535, 'model_index': 105, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.535, 'model_index': 106, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5375, 'model_index': 107, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5285, 'model_index': 108, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.30174999999999996, 'model_index': 109, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.537, 'model_index': 110, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.523, 'model_index': 111, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5277499999999999, 'model_index': 112, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.52775, 'model_index': 113, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.30825, 'model_index': 114, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5242500000000001, 'model_index': 115, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5355000000000001, 'model_index': 116, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.538, 'model_index': 117, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5295000000000001, 'model_index': 118, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.27549999999999997, 'model_index': 119, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1e-05, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.40825, 'model_index': 120, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.41275, 'model_index': 121, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.41450000000000004, 'model_index': 122, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.415, 'model_index': 123, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.16725, 'model_index': 124, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.41675, 'model_index': 125, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.41275, 'model_index': 126, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.41975, 'model_index': 127, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.409, 'model_index': 128, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.16249999999999998, 'model_index': 129, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.40374999999999994, 'model_index': 130, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.40725, 'model_index': 131, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.41275, 'model_index': 132, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.42325, 'model_index': 133, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.1415, 'model_index': 134, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5305, 'model_index': 135, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.53725, 'model_index': 136, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5305000000000001, 'model_index': 137, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.535, 'model_index': 138, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.29974999999999996, 'model_index': 139, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.52525, 'model_index': 140, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.536, 'model_index': 141, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.5342500000000001, 'model_index': 142, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.53075, 'model_index': 143, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.30275, 'model_index': 144, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5265, 'model_index': 145, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.5285, 'model_index': 146, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.533, 'model_index': 147, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.5325, 'model_index': 148, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.281, 'model_index': 149, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 0.0001, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.40575, 'model_index': 150, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.41850000000000004, 'model_index': 151, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.41775, 'model_index': 152, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.40225000000000005, 'model_index': 153, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.17400000000000002, 'model_index': 154, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.41075, 'model_index': 155, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.42024999999999996, 'model_index': 156, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.41625, 'model_index': 157, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.406, 'model_index': 158, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.13175, 'model_index': 159, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.41325, 'model_index': 160, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.39849999999999997, 'model_index': 161, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.4145, 'model_index': 162, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.42074999999999996, 'model_index': 163, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.1315, 'model_index': 164, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': True, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.527, 'model_index': 165, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.53075, 'model_index': 166, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.53175, 'model_index': 167, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.523, 'model_index': 168, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.27549999999999997, 'model_index': 169, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.999, 0.99], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.52975, 'model_index': 170, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.52625, 'model_index': 171, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.513, 'model_index': 172, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.538, 'model_index': 173, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.296, 'model_index': 174, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.85, 0.85], 'K': 33, 'c': -0.5, 'S': 0}, {'accuracy': 0.5355000000000001, 'model_index': 175, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 0}, {'accuracy': 0.52875, 'model_index': 176, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 250.0}, {'accuracy': 0.53, 'model_index': 177, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 0, 'c': -0.5, 'S': 33.333333333333336}, {'accuracy': 0.53325, 'model_index': 178, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 250, 'c': -0.5, 'S': 0}, {'accuracy': 0.291, 'model_index': 179, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 10, 'l2': 1, 'use_adam': False, 'b1_b2': [0.9, 0.88], 'K': 33, 'c': -0.5, 'S': 0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Me guardé el score como .json\n",
    "# with open(\"model_score_01.json\", \"w\") as file:\n",
    "#     json.dump(model_score, file, indent=4)\n",
    "model_score_01 : list[dict] = {}\n",
    "with open(\"model_score_01.json\", \"r\") as file:\n",
    "    model_score_01 = json.load(file)\n",
    "print(model_score_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744352ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\n",
      "-> Loss Mean = 1.9616350958766593\n",
      "Epoch 100\n",
      "-> Loss Mean = 1.3358544359519229\n",
      "-> Difference = -0.6257806599247364\n",
      "Epoch 150\n",
      "-> Loss Mean = 1.0555957384103685\n",
      "-> Difference = -0.2802586975415544\n",
      "Epoch 200\n",
      "-> Loss Mean = 0.9199722695041637\n",
      "-> Difference = -0.1356234689062048\n",
      "Epoch 250\n",
      "-> Loss Mean = 0.8654609289179276\n",
      "-> Difference = -0.05451134058623608\n",
      "Epoch 300\n",
      "-> Loss Mean = 0.8396746027506442\n",
      "-> Difference = -0.02578632616728338\n",
      "Epoch 350\n",
      "-> Loss Mean = 0.8154881106829187\n",
      "-> Difference = -0.024186492067725496\n",
      "Epoch 400\n",
      "-> Loss Mean = 0.7925827538333036\n",
      "-> Difference = -0.022905356849615144\n",
      "Epoch 450\n",
      "-> Loss Mean = 0.7714030738906817\n",
      "-> Difference = -0.02117967994262182\n",
      "Epoch 500\n",
      "-> Loss Mean = 0.7663956197291596\n",
      "-> Difference = -0.005007454161522151\n"
     ]
    }
   ],
   "source": [
    "# Mejor modelo:\n",
    "M1_01 : models.RedNeuronal = models.RedNeuronal(M=[784, 100, 80, 48], h=['relu', 'relu', 'softmax'])\n",
    "M1_01.stochastic_gradient_descent(\n",
    "    np.array(X_train),\n",
    "    np.array(Y_train),\n",
    "    epochs=500,\n",
    "    learning_rate=model_score_01[48]['lr_range'],\n",
    "    batch_size_2_pow=model_score_01[48]['batch_size_2'], # El batch size toma el mismo valor que la cantidad de muestras\n",
    "    K=model_score_01[48]['K'],\n",
    "    c=model_score_01[48]['c'] if model_score_01[48]['S'] != 0 else 0,\n",
    "    S=model_score_01[48]['S'],\n",
    "    use_adam=model_score_01[48]['use_adam'],\n",
    "    b1=model_score_01[48]['b1_b2'][0],\n",
    "    b2=model_score_01[48]['b1_b2'][1],\n",
    "    L2=model_score_01[48]['l2'],\n",
    "    print_results_rate=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c99a053",
   "metadata": {},
   "source": [
    "El modelo no utiliza Adam, a partir de este modelo, busco parámetros de Adam para ver si mejora la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66374412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs : int = 500\n",
    "# b1_and_b2_values : list[tuple[float, float]] = [(0.999, 0.99), (0.85, 0.85), (0.95, 0.95), (0.9, 0.88), (0.9999, 0.999)]\n",
    "# cross_validation : models.CrossValidation = models.CrossValidation(\n",
    "#     np.array(X_train),\n",
    "#     np.array(Y_train),\n",
    "#     epochs=epochs,\n",
    "#     num_folds=4,\n",
    "#     learning_rate_range=model_score_01[48]['lr_range'],\n",
    "#     batch_size_2_pow_values=[model_score_01[48]['batch_size_2']],\n",
    "#     K_values=[model_score_01[48]['K']],\n",
    "#     c_value=0,\n",
    "#     S_values=[model_score_01[48]['S']],\n",
    "#     b1_and_b2_values=b1_and_b2_values,\n",
    "#     L2_values=[model_score_01[48]['l2']],\n",
    "# )\n",
    "# model_score_02 : list[dict] = cross_validation.evaluate_hiperparameters(M=[784,100,80,48], h=['relu', 'relu', 'softmax'])\n",
    "# cross_validation.print_n_scores(model_score_02, 10)\n",
    "\n",
    "# output\n",
    "\n",
    "# Cantidad de iteraciones estimada: 10\n",
    "# {'accuracy': np.float64(0.5754999999999999), 'model_index': 9, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.9999, 0.999), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.57475), 'model_index': 7, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.95, 0.95), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.57275), 'model_index': 5, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.999, 0.99), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.5722499999999999), 'model_index': 6, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.85, 0.85), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.5702499999999999), 'model_index': 8, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': False, 'b1_b2': (0.9, 0.88), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.31675), 'model_index': 3, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': (0.9, 0.88), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.31575), 'model_index': 2, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': (0.95, 0.95), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.30775), 'model_index': 1, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': (0.85, 0.85), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.24175), 'model_index': 0, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': (0.999, 0.99), 'K': 250, 'c': 0, 'S': 0}\n",
    "# {'accuracy': np.float64(0.23825), 'model_index': 4, 'lr_range': [0.0001, 1e-05], 'batch_size_2': 1000, 'l2': 0.0001, 'use_adam': True, 'b1_b2': (0.9999, 0.999), 'K': 250, 'c': 0, 'S': 0}\n",
    "\n",
    "# M1_01 sigue siendo mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e2db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"model_score_02.json\", \"w\") as file:\n",
    "#     json.dump(model_score_02, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3b5fd0",
   "metadata": {},
   "source": [
    "A partir de M1_01, pruebo distintas arquitecturas de red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3156c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "CrossValidation.evaluate_architectures() got an unexpected keyword argument 'M'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m epochs : \u001b[38;5;28mint\u001b[39m = \u001b[32m500\u001b[39m\n\u001b[32m      2\u001b[39m cross_validation : models.CrossValidation = models.CrossValidation(\n\u001b[32m      3\u001b[39m     np.array(X_train),\n\u001b[32m      4\u001b[39m     np.array(Y_train),\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m     L2_values=[model_score_01[\u001b[32m48\u001b[39m][\u001b[33m'\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m'\u001b[39m]],\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m model_score_03 : \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] = \u001b[43mcross_validation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_architectures\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mM\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m784\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m48\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mh\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msoftmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msoftmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrelu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msoftmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_adam\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m cross_validation.print_n_scores(model_score_03, \u001b[32m10\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: CrossValidation.evaluate_architectures() got an unexpected keyword argument 'M'"
     ]
    }
   ],
   "source": [
    "epochs : int = 500\n",
    "cross_validation : models.CrossValidation = models.CrossValidation(\n",
    "    np.array(X_train),\n",
    "    np.array(Y_train),\n",
    "    epochs=epochs,\n",
    "    num_folds=4,\n",
    "    learning_rate_range=model_score_01[48]['lr_range'],\n",
    "    batch_size_2_pow_values=[model_score_01[48]['batch_size_2']],\n",
    "    K_values=[model_score_01[48]['K']],\n",
    "    c_value=0,\n",
    "    S_values=[model_score_01[48]['S']],\n",
    "    b1_and_b2_values=[model_score_01[48]['b1_b2']],\n",
    "    L2_values=[model_score_01[48]['l2']],\n",
    ")\n",
    "model_score_03 : list[dict] = cross_validation.evaluate_architectures(\n",
    "    M_values=[\n",
    "        [784,100,80,48],\n",
    "        [784,80,100,48],\n",
    "        [784,500,250,48],\n",
    "        [784,250,500,48],\n",
    "        [784,10,500,48],\n",
    "        [784,500,10,48],\n",
    "        [784,100,500,100,48],\n",
    "        [784,50,80,50,48],\n",
    "        [784,100,500,100,500,48],\n",
    "        [784,50,80,50,80,48],\n",
    "    ], \n",
    "    h_values=[\n",
    "        ['relu', 'relu', 'softmax'],\n",
    "        ['relu', 'relu', 'relu', 'softmax'],\n",
    "        ['relu', 'relu', 'relu', 'relu', 'softmax'],\n",
    "    ], \n",
    "    use_adam=False,\n",
    ")\n",
    "cross_validation.print_n_scores(model_score_03, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
